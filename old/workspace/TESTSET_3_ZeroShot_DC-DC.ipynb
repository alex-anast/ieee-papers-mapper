{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8da2286-887b-4791-bfb7-4d55e3ffe0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET (reloading independent code fragment for now sampled excel)\n",
    "\n",
    "# Import CNN Zero-Shot & other necessary stuff\n",
    "from transformers import pipeline  # It takes  time here\n",
    "# For data input and data cleaning\n",
    "import pandas as pd\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from numpy import NaN\n",
    "import time\n",
    "\n",
    "# Available directories (input yours for personal use)\n",
    "cep_data_dir = \"/home/aan0709@tmme/pcu-research-mapping/data/\"\n",
    "\n",
    "working_dir = \"TEST/\"    # CHANGE WORKING DIRECTORY INSIDE IEEE XPLORE FOLDER\n",
    "\n",
    "# For data importing\n",
    "def openExcel(excel_name, sheet_name, directory):\n",
    "    df = pd.read_excel(directory + excel_name + \".xlsx\", sheet_name=sheet_name)\n",
    "    return df\n",
    "\n",
    "def cleanIndexes(df):\n",
    "    temp_ls = df.columns\n",
    "    for i in df.columns:\n",
    "        if i == \"abstract\": break\n",
    "        df.drop(columns=[i], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Select INPUT EXCEL\n",
    "file_name = \"TESTSET_DC-DC_answered\"    # -> I have edited the Affiliations and the Keywords part\n",
    "\n",
    "df = openExcel(file_name, \"Sheet1\", cep_data_dir + working_dir)\n",
    "\n",
    "df = cleanIndexes(df)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bfdd42-59e5-4acb-b29a-bac2109430fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds elapsed:  10.904866695404053\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "classifierGPU0 = pipeline(\"zero-shot-classification\", model='facebook/bart-large-mnli', device=0)\n",
    "end = time.time()\n",
    "print(\"seconds elapsed: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d64c3d-31bf-4434-8c81-80e68d65b3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "Author_Keywords = \"index_terms.author_terms.terms\"\n",
    "IEEE_Keywords = \"index_terms.ieee_terms.terms\"\n",
    "\n",
    "# Keep only those w/ IEEE Key\n",
    "ieee_key = \"DC-DC power converters\"\n",
    "df_new = pd.DataFrame()\n",
    "for i in range(len(df[\"Manual Judgement\"])):\n",
    "    if ieee_key in df.loc[i, IEEE_Keywords]:\n",
    "        df_new = df_new.append(df.loc[i])\n",
    "\n",
    "keeping = len(df_new)\n",
    "df_new.reset_index(drop=True, inplace=True)\n",
    "print(keeping)\n",
    "\n",
    "# Those that will be appended in the end will have been predefined as wrong\n",
    "for  i in range(len(df)):\n",
    "    flag = True\n",
    "    for j in range(len(df_new)):\n",
    "        if df_new.loc[j, \"abstract\"] == df.loc[i, \"abstract\"]:\n",
    "            flag = False\n",
    "            break\n",
    "    if flag:\n",
    "        df_new = df_new.append(df.loc[i])\n",
    "        df_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_new[\"ZeroShot Judgement\"] = NaN\n",
    "for i in range(len(df_new)-1, keeping-1, -1):\n",
    "    df_new.loc[i, \"ZeroShot Judgement\"] = 0\n",
    "\n",
    "df = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c909add8-e27b-4051-8888-d69888616283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC-DC power converters: 19/50, w/ key 13/19\n"
     ]
    }
   ],
   "source": [
    "Author_Keywords = \"index_terms.author_terms.terms\"\n",
    "IEEE_Keywords = \"index_terms.ieee_terms.terms\"\n",
    "\n",
    "# count 0s and 1s:\n",
    "count1 = 0\n",
    "count_key = 0\n",
    "ieee_key = \"DC-DC power converters\"\n",
    "\n",
    "for i in range(len(df[\"Manual Judgement\"])):\n",
    "    if str(int(df.loc[i, \"Manual Judgement\"])) == '1':\n",
    "        count1 += 1\n",
    "        if ieee_key in df.loc[i, IEEE_Keywords]:\n",
    "            count_key += 1\n",
    "\n",
    "print(\"DC-DC power converters: %d/50, w/ key %d/%d\" % (count1, count_key, count1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79a30330-7980-479c-b821-66f06c46403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 0\n",
    "\n",
    "positive_outcome = \"dc-dc converter dc/dc converter\"\n",
    "# negative_outcome = \"not traction inverter\"\n",
    "\n",
    "candidate_labels = [positive_outcome] # , negative_outcome]\n",
    "hypothesis_template = \"The research is about {}?\"    # Categorization question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73e2b179-3385-48c3-aa11-ae26cba6c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 1\n",
    "\n",
    "positive_outcome = \"dc-dc converter dc/dc converter LLC resonant dc-dc converter double active bridge DAB dc-dc converter\"\n",
    "negative_outcome = \"pulse width modulation PWM converter AC-DC AC/DC converter DC-AC DC/AC converter AC-AC AC/AC converter wireless converter\"\n",
    "\n",
    "candidate_labels = [\"dc-dc converter dc/dc converter\", \"LLC resonant dc-dc converter\", \"double active bridge DAB dc-dc converter\",\n",
    "                    \"pulse width modulation PWM converter\", \"AC-DC AC/DC converter\", \"DC-AC DC/AC converter\", \"AC-AC AC/AC converter\", \"wireless converter\"]\n",
    "\n",
    "hypothesis_template = \"The research is about {}?\"    # Categorization question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7838c9eb-54c0-43d4-9e59-2ee8aceeb282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 - \n",
    "\n",
    "positive_outcome = \"dc-dc dc/dc converter LLC resonant converter double active bridge DAB converter\"\n",
    "negative_outcome = \"pulse width modulation PWM converter AC-DC AC/DC converter DC-AC DC/AC converter AC-AC AC/AC converter wireless converter\"\n",
    "\n",
    "candidate_labels = [\"dc-dc dc/dc converter\", \"LLC resonant converter\", \"double active bridge DAB converter\",\n",
    "                    \"pulse width modulation PWM\", \"AC-DC AC/DC converter\", \"DC-AC DC/AC converter\", \"AC-AC AC/AC converter\", \"wireless\"]\n",
    "\n",
    "hypothesis_template = \"The research is about {}?\"    # Categorization question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a23804-995a-4041-a64b-b34169a62107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35\n",
      "Time: 0 min 13.755 sec\n",
      "From 50 papers, the 40 are CORRECT and the 10 are WRONG ( 80.00 percent correct )\n",
      "\n",
      "0.4\n",
      "Time: 0 min 13.973 sec\n",
      "From 50 papers, the 40 are CORRECT and the 10 are WRONG ( 80.00 percent correct )\n",
      "\n",
      "0.45\n",
      "Time: 0 min 13.600 sec\n",
      "From 50 papers, the 41 are CORRECT and the 9 are WRONG ( 82.00 percent correct )\n",
      "\n",
      "0.5\n",
      "Time: 0 min 13.423 sec\n",
      "From 50 papers, the 43 are CORRECT and the 7 are WRONG ( 86.00 percent correct )\n",
      "\n",
      "0.55\n",
      "Time: 0 min 12.598 sec\n",
      "From 50 papers, the 42 are CORRECT and the 8 are WRONG ( 84.00 percent correct )\n",
      "\n",
      "0.6\n",
      "Time: 0 min 13.377 sec\n",
      "From 50 papers, the 42 are CORRECT and the 8 are WRONG ( 84.00 percent correct )\n",
      "\n",
      "0.65\n",
      "Time: 0 min 13.335 sec\n",
      "From 50 papers, the 42 are CORRECT and the 8 are WRONG ( 84.00 percent correct )\n",
      "\n",
      "0.7\n",
      "Time: 0 min 14.153 sec\n",
      "From 50 papers, the 42 are CORRECT and the 8 are WRONG ( 84.00 percent correct )\n",
      "\n",
      "0.75\n",
      "Time: 0 min 13.591 sec\n",
      "From 50 papers, the 42 are CORRECT and the 8 are WRONG ( 84.00 percent correct )\n",
      "\n",
      "0.8\n",
      "Time: 0 min 13.288 sec\n",
      "From 50 papers, the 43 are CORRECT and the 7 are WRONG ( 86.00 percent correct )\n",
      "\n",
      "0.85\n",
      "Time: 0 min 13.784 sec\n",
      "From 50 papers, the 42 are CORRECT and the 8 are WRONG ( 84.00 percent correct )\n",
      "\n",
      "0.9\n",
      "Time: 0 min 13.524 sec\n",
      "From 50 papers, the 40 are CORRECT and the 10 are WRONG ( 80.00 percent correct )\n",
      "\n",
      "0.95\n",
      "Time: 0 min 13.812 sec\n",
      "From 50 papers, the 37 are CORRECT and the 13 are WRONG ( 74.00 percent correct )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "percentages = []\n",
    "for perc_loop in range(35, 100, 5):\n",
    "\n",
    "    en_stopwords = []\n",
    "    en_stopwords = list(get_stop_words('en'))         #About 900 stopwords\n",
    "    nltk_words = list(stopwords.words('english'))     #About 150 stopwords\n",
    "    en_stopwords.extend(nltk_words)\n",
    "\n",
    "    lemma = WordNetLemmatizer()\n",
    "\n",
    "    Author_Keywords = \"index_terms.author_terms.terms\"\n",
    "    IEEE_Keywords = \"index_terms.ieee_terms.terms\"\n",
    "\n",
    "    zero_shot_judgement = []\n",
    "    # df[\"ZeroShot Judgement\"] = NaN\n",
    "\n",
    "    count_all = len(df)\n",
    "    count_diff = 0\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    final_judgement_dict = {}\n",
    "\n",
    "    # for i in range(len(df)):\n",
    "    for i in range(len(df)):\n",
    "        data = \"\"\n",
    "\n",
    "        # Where to search\n",
    "        if isinstance(df.loc[i, \"abstract\"], str):\n",
    "            data += df.loc[i, \"abstract\"]\n",
    "        if isinstance(df.loc[i, \"title\"], str):\n",
    "            data += \" \" + df.loc[i, \"title\"]\n",
    "        exception_to_str = df.loc[i, IEEE_Keywords]\n",
    "        if isinstance(exception_to_str, str):\n",
    "            exception_to_str = \" \".join(df.loc[i, IEEE_Keywords].split(\";\"))\n",
    "            data += \" \" + exception_to_str\n",
    "        exception_to_str = df.loc[i, Author_Keywords]\n",
    "        if isinstance(exception_to_str, str):\n",
    "            exception_to_str = \" \".join(df.loc[i, Author_Keywords].split(\";\"))\n",
    "            data += \" \" + exception_to_str\n",
    "            printing_data = data\n",
    "\n",
    "        # Data Cleaning with NLTK, NumPy\n",
    "        tokens = regexp_tokenize(data, pattern=r\"\\s|[\\.,;'()]\", gaps=True)\n",
    "        words = []\n",
    "        for k in tokens:\n",
    "            if k not in en_stopwords:\n",
    "                k = lemma.lemmatize(k)\n",
    "            words.append(k)\n",
    "        data = \" \".join(words)\n",
    "\n",
    "        # print(data)\n",
    "\n",
    "        # Here the data has been cleaned\n",
    "        input_text = data\n",
    "\n",
    "        # Rienforcing the data with keyword\n",
    "        tokens = regexp_tokenize(data, pattern=r\"\\s|[\\.,;'()]\", gaps=True)\n",
    "        for j in tokens:\n",
    "            if j in candidate_labels[0]:\n",
    "                data += j\n",
    "\n",
    "        start_judge = time.time()\n",
    "        # Extract the probabilities from the CNN\n",
    "        final_judgement_dict = classifierGPU0(input_text, candidate_labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
    "\n",
    "        end_judge = time.time()\n",
    "\n",
    "        if final_judgement_dict[\"labels\"][0] in positive_outcome and final_judgement_dict[\"scores\"][0] > perc_loop/100.0:\n",
    "            zero_shot_judge = 1\n",
    "        else:\n",
    "            zero_shot_judge = 0\n",
    "        # print(zero_shot_judge)\n",
    "        zero_shot_judgement.append(zero_shot_judge)\n",
    "        df.loc[i, \"ZeroShot Judgement\"] = float(zero_shot_judge)\n",
    "\n",
    "        # print(data)\n",
    "\n",
    "\n",
    "    while len(zero_shot_judgement) < len(df):\n",
    "        zero_shot_judgement.append(0)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    # Print differences\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i, \"ZeroShot Judgement\"] != df.loc[i, \"Manual Judgement\"]:\n",
    "            count_diff += 1\n",
    "\n",
    "            \"\"\"print(df.loc[i, \"Manual Judgement\"])\n",
    "            print(\"----- DECISION ----- :\")\n",
    "            print(i)\n",
    "            if str(zero_shot_judgement[i]) == \"1\":\n",
    "                print(\"-- It is included --\")\n",
    "            else:\n",
    "                print(\"-- It is NNNOOOTTT included --\")    # Visual exageration to easily spot answer\n",
    "            print()\n",
    "            if isinstance(df.loc[i, Author_Keywords], str): auth_keys = df.loc[i, Author_Keywords].split(\";\")\n",
    "            else: auth_keys = \"\"\n",
    "            if isinstance(df.loc[i, IEEE_Keywords], str): ieee_keys = df.loc[i, IEEE_Keywords].split(\";\")\n",
    "            else: ieee_keys = \"\"\n",
    "            print(\"Abstract :\")\n",
    "            print(df.loc[i, \"abstract\"], \"\\n\")\n",
    "            print(\"Document Title :\")\n",
    "            print(df.loc[i, \"title\"], \"\\n\")\n",
    "            print(\"Author Keywords :\")\n",
    "            [print(\"-> \", x) for x in auth_keys]\n",
    "            print()\n",
    "            print(\"IEEE Keywords :\")\n",
    "            [print(\"-> \", x) for x in ieee_keys]\"\"\"\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i, \"ZeroShot Judgement\"] == \"1\":\n",
    "            count += 1\n",
    "\n",
    "    percentages.append((count_all-count_diff)/count_all)\n",
    "    print(perc_loop/100)\n",
    "    m, s = divmod(end - start, 60)\n",
    "    print(\"Time: %d min %0.3f sec\" % (m,s))\n",
    "    print(\"From %d papers, the %d are CORRECT and the %d are WRONG ( %.2f percent correct )\\n\" % (count_all, count_all-count_diff, count_diff, (100*(count_all-count_diff)/count_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98e8b8-5118-4a67-adf4-49cef424880d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP (python3.7)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
